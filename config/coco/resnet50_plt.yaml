# default num_head = 2
criterions:
  PerformanceLoss:
    def_file: ./loss/PriorFocalModifierLoss.py
    loss_params: {gamma_neg: 3, gamma_pos: 0, clip: 0.05, disable_torch_grad_focal_loss: True}
    optim_params: null
    weight: 1.0
last: false
# apply incremental pca to remove main components
apply_ipca: false
num_components: 1024
model_dir: null
tuning_memory: false
banlaced_networks:
  feat_model:
    def_file: ./models/ResNet50Feature.py
    fix: false
    optim_params: {lr: 0.001, momentum: 0.9, weight_decay: 0.0001}
    scheduler_params: {coslr: false, warmup: false,  gamma: 0.1, step_size: 12}
    params: {dataset: MLT_coco, feat_dim: 1024, dropout: null, stage1_weights: false, use_fc: true}
  additive_attention:
    def_file: ./models/AdditivetionAttention.py
    fix: false
    optim_params: {lr: 0.001, momentum: 0.9, weight_decay: 0.0001}
    scheduler_params: {coslr: false, warmup: false,  gamma: 0.1, step_size: 18}
    params: {dataset: MLT_coco, key_size: 1024, query_size: 1024, num_hiddens: 1024}
  classifier:
    def_file: ./models/CausalNormClassifier.py
    optim_params: {lr: 0.0001, momentum: 0.9, weight_decay: 0.0001}
    scheduler_params: {coslr: false, warmup: false, steplr: false, gamma: 0.1, step_size: 18}
    params: {dataset: MLT_coco, feat_dim: 1024, num_classes: 80, stage1_weights: false, use_effect: true, num_head: 1, tau: 16.0, alpha: 2, gamma: 0.03125}
head_networks:
  feat_model:
    def_file: ./models/ResNet50Feature.py
    fix: false
    optim_params: {lr: 0.001, momentum: 0.9, weight_decay: 0.0001}
    scheduler_params: {coslr: false, warmup: false,  gamma: 0.1, step_size: 24}
    params: {dataset: MLT_coco, feat_dim: 1024, dropout: null, stage1_weights: false, use_fc: true}
  classifier:
    def_file: ./models/HeadNormClassifier.py
    optim_params: {lr: 0.0001, momentum: 0.9, weight_decay: 0.0001}
    scheduler_params: {coslr: false, warmup: false, gamma: 0.1, step_size: 24}
    params: {dataset: MLT_coco, feat_dim: 1024, num_classes: 80, stage1_weights: false, use_effect: true, num_head: 1, tau: 16.0, alpha: 2, gamma: 0.03125}
tail_networks:
  feat_model:
    def_file: ./models/ResNet50Feature.py
    fix: false
    optim_params: {lr: 0.001, momentum: 0.9, weight_decay: 0.0001}
    scheduler_params: {coslr: false, warmup: false,  gamma: 0.1, step_size: 12}
    params: {dataset: MLT_coco, feat_dim: 1024, dropout: null, stage1_weights: false, use_fc: true}
  classifier:
    def_file: ./models/TailNormClassifier.py
    optim_params: {lr: 0.0001, momentum: 0.9, weight_decay: 0.0001}
    scheduler_params: {coslr: false, warmup: false, gamma: 0.1, step_size: 12}
    params: {dataset: MLT_coco, feat_dim: 1024, num_classes: 80, stage1_weights: false, use_effect: true, num_head: 1, tau: 16.0, alpha: 2, gamma: 0.03125}

shuffle: false
training_opt:
  optimizer: adam
  backbone: resnet50
  batch_size: 32
  dataset: MLT_coco
  distribution_path: /hdd8//dataset/coco/coco_LT_Missing_current/40/distribution.txt
  co_occurrence_matrix: /hdd8//dataset/coco/coco_LT_Missing_current/40/co-occurrence.npy
  train_annatation_path: /hdd8//dataset/coco/coco_LT_Missing_current/40/LT_train.json
  no_missing_path: /hdd8//dataset/coco/coco_LT_Missing_current/0/LT_train.json
  val_annatation_path: /hdd8//dataset/coco/annotations/LT_coco_val.json
  train_data_path: /hdd8//dataset/coco/images/train2017/
  val_data_path: /hdd8//dataset/coco/images/val2017/
  display_step: 10
  display_grad: False
  display_grad_step: 10
  feature_dim: 1024
  log_dir: /home//project/NLT-multi-label-classification/log/NP
  log_root: /home//project/NLT-multi-label-classification/log/NP
  num_classes: 80
  num_epochs: 40
  head_class_number: 100
  tail_class_number: 20
  num_workers: 8
  open_threshold: 0.1
  sampler: null
  sub_dir: models
  gamma: 2
  gpu_ids: 1